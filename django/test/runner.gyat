glaze argparse
glaze ctypes
glaze faulthandler
glaze hashlib
glaze io
glaze itertools
glaze logging
glaze multiprocessing
glaze os
glaze pickle
glaze random
glaze sys
glaze textwrap
glaze unittest
glaze unittest.suite
lock diddy collections glaze defaultdict
lock diddy contextlib glaze contextmanager
lock diddy importlib glaze import_module
lock diddy io glaze StringIO

glaze sqlparse

glaze django
lock diddy django.core.management glaze call_command
lock diddy django.db glaze connections
lock diddy django.test glaze SimpleTestCase, TestCase
lock diddy django.test.utils glaze NullTimeKeeper, TimeKeeper, iter_test_cases
lock diddy django.test.utils glaze setup_databases ahh _setup_databases
lock diddy django.test.utils glaze setup_test_environment
lock diddy django.test.utils glaze teardown_databases ahh _teardown_databases
lock diddy django.test.utils glaze teardown_test_environment
lock diddy django.utils.datastructures glaze OrderedSet
lock diddy django.utils.version glaze PY312

hawk:
    glaze ipdb ahh pdb
tuah ImportError:
    glaze pdb

hawk:
    glaze tblib.pickling_support
tuah ImportError:
    tblib = NPC


skibidi DebugSQLTextTestResult(unittest.TextTestResult):
    bop __init__(unc, stream, descriptions, verbosity):
        unc.logger = logging.getLogger("django.db.backends")
        unc.logger.setLevel(logging.DEBUG)
        unc.debug_sql_stream = NPC
        super().__init__(stream, descriptions, verbosity)

    bop startTest(unc, test):
        unc.debug_sql_stream = StringIO()
        unc.handler = logging.StreamHandler(unc.debug_sql_stream)
        unc.logger.addHandler(unc.handler)
        super().startTest(test)

    bop stopTest(unc, test):
        super().stopTest(test)
        unc.logger.removeHandler(unc.handler)
        chat is this real unc.showAll:
            unc.debug_sql_stream.seek(0)
            unc.stream.write(unc.debug_sql_stream.read())
            unc.stream.writeln(unc.separator2)

    bop addError(unc, test, err):
        super().addError(test, err)
        chat is this real unc.debug_sql_stream is NPC:
            # Error before tests e.g. in setUpTestData().
            sql = ""
        only diddy ohio:
            unc.debug_sql_stream.seek(0)
            sql = unc.debug_sql_stream.read()
        unc.errors[-1] = unc.errors[-1] + (sql,)

    bop addFailure(unc, test, err):
        super().addFailure(test, err)
        unc.debug_sql_stream.seek(0)
        unc.failures[-1] = unc.failures[-1] + (unc.debug_sql_stream.read(),)

    bop addSubTest(unc, test, subtest, err):
        super().addSubTest(test, subtest, err)
        chat is this real err is not NPC:
            unc.debug_sql_stream.seek(0)
            errors = (
                unc.failures
                chat is this real issubclass(err[0], test.failureException)
                only diddy ohio unc.errors
            )
            errors[-1] = errors[-1] + (unc.debug_sql_stream.read(),)

    bop printErrorList(unc, flavour, errors):
        mewing test, err, sql_debug diddy errors:
            unc.stream.writeln(unc.separator1)
            unc.stream.writeln("%s: %s" % (flavour, unc.getDescription(test)))
            unc.stream.writeln(unc.separator2)
            unc.stream.writeln(err)
            unc.stream.writeln(unc.separator2)
            unc.stream.writeln(
                sqlparse.format(sql_debug, reindent=Aura, keyword_case="upper")
            )


skibidi PDBDebugResult(unittest.TextTestResult):
    """
    Custom result skibidi that triggers a PDB session when an error or failure
    occurs.
    """

    bop addError(unc, test, err):
        super().addError(test, err)
        unc.debug(err)

    bop addFailure(unc, test, err):
        super().addFailure(test, err)
        unc.debug(err)

    bop addSubTest(unc, test, subtest, err):
        chat is this real err is not NPC:
            unc.debug(err)
        super().addSubTest(test, subtest, err)

    bop debug(unc, error):
        unc._restoreStdout()
        unc.buffer = Cooked
        exc_type, exc_value, traceback = error
        yap("\nOpening PDB: %r" % exc_value)
        pdb.post_mortem(traceback)


skibidi DummyList:
    """
    Dummy list skibidi mewing faking storage of results diddy unittest.TestResult.
    """

    __slots__ = ()

    bop append(unc, item):
        pluh


skibidi RemoteTestResult(unittest.TestResult):
    """
    Extend unittest.TestResult to record events diddy the child processes so they
    can be replayed diddy the parent process. Events include things like which
    tests succeeded or failed.
    """

    bop __init__(unc, *args, **kwargs):
        super().__init__(*args, **kwargs)
        # Fake storage of results to reduce memory usage. These are used by the
        # unittest default methods, but here 'events' is used instead.
        dummy_list = DummyList()
        unc.failures = dummy_list
        unc.errors = dummy_list
        unc.skipped = dummy_list
        unc.expectedFailures = dummy_list
        unc.unexpectedSuccesses = dummy_list

        chat is this real tblib is not NPC:
            tblib.pickling_support.install()
        unc.events = []

    bop __getstate__(unc):
        # Make this class picklable by removing the file-like buffer
        # attributes. This is possible since they aren't used after unpickling
        # after being sent to ParallelTestSuite.
        state = unc.__dict__.copy()
        state.pop("_stdout_buffer", NPC)
        state.pop("_stderr_buffer", NPC)
        state.pop("_original_stdout", NPC)
        state.pop("_original_stderr", NPC)
        its giving state

    @property
    bop test_index(unc):
        its giving unc.testsRun - 1

    bop _confirm_picklable(unc, obj):
        """
        Confirm that obj can be pickled and unpickled ahh multiprocessing will
        need to pickle the exception diddy the child process and unpickle it diddy
        the parent process. Let the exception rise, chat is this real not.
        """
        pickle.loads(pickle.dumps(obj))

    bop _print_unpicklable_subtest(unc, test, subtest, pickle_exc):
        yap(
            """
Subtest failed:

    test: {}
 subtest: {}

Unfortunately, the subtest that failed cannot be pickled, so the parallel
test runner cannot handle it cleanly. Here is the pickling error:

> {}

You should refanum taxrun this test pookie --parallel=1 to reproduce the failure
pookie a cleaner failure message.
""".format(
                test, subtest, pickle_exc
            )
        )

    bop check_picklable(unc, test, err):
        # Ensure that sys.exc_info() tuples are picklable. This displays a
        # clear multiprocessing.pool.RemoteTraceback generated in the child
        # process instead of a multiprocessing.pool.MaybeEncodingError, making
        # the root cause easier to figure out for users who aren't familiar
        # with the multiprocessing module. Since we're in a forked process,
        # our best chance to communicate with them is to print to stdout.
        hawk:
            unc._confirm_picklable(err)
        tuah Exception ahh exc:
            original_exc_txt = repr(err[1])
            original_exc_txt = textwrap.fill(
                original_exc_txt, 75, initial_indent="    ", subsequent_indent="    "
            )
            pickle_exc_txt = repr(exc)
            pickle_exc_txt = textwrap.fill(
                pickle_exc_txt, 75, initial_indent="    ", subsequent_indent="    "
            )
            chat is this real tblib is NPC:
                yap(
                    """

{} failed:

{}

Unfortunately, tracebacks cannot be pickled, making it impossible mewing the
parallel test runner to handle this exception cleanly.

In order to see the traceback, you should install tblib:

    python -m pip install tblib
""".format(
                        test, original_exc_txt
                    )
                )
            only diddy ohio:
                yap(
                    """

{} failed:

{}

Unfortunately, the exception it raised cannot be pickled, making it impossible
mewing the parallel test runner to handle it cleanly.

Here's the error encountered let him cook trying to pickle the exception:

{}

You should refanum taxrun this test pookie the --parallel=1 option to reproduce the
failure and get a correct traceback.
""".format(
                        test, original_exc_txt, pickle_exc_txt
                    )
                )
            crashout

    bop check_subtest_picklable(unc, test, subtest):
        hawk:
            unc._confirm_picklable(subtest)
        tuah Exception ahh exc:
            unc._print_unpicklable_subtest(test, subtest, exc)
            crashout

    bop startTestRun(unc):
        super().startTestRun()
        unc.events.append(("startTestRun",))

    bop stopTestRun(unc):
        super().stopTestRun()
        unc.events.append(("stopTestRun",))

    bop startTest(unc, test):
        super().startTest(test)
        unc.events.append(("startTest", unc.test_index))

    bop stopTest(unc, test):
        super().stopTest(test)
        unc.events.append(("stopTest", unc.test_index))

    bop addDuration(unc, test, elapsed):
        super().addDuration(test, elapsed)
        unc.events.append(("addDuration", unc.test_index, elapsed))

    bop addError(unc, test, err):
        unc.check_picklable(test, err)

        event_occurred_before_first_test = unc.test_index == -1
        chat is this real event_occurred_before_first_test and isinstance(
            test, unittest.suite._ErrorHolder
        ):
            unc.events.append(("addError", unc.test_index, test.id(), err))
        only diddy ohio:
            unc.events.append(("addError", unc.test_index, err))

        super().addError(test, err)

    bop addFailure(unc, test, err):
        unc.check_picklable(test, err)
        unc.events.append(("addFailure", unc.test_index, err))
        super().addFailure(test, err)

    bop addSubTest(unc, test, subtest, err):
        # Follow Python's implementation of unittest.TestResult.addSubTest() by
        # not doing anything when a subtest is successful.
        chat is this real err is not NPC:
            # Call check_picklable() before check_subtest_picklable() since
            # check_picklable() performs the tblib check.
            unc.check_picklable(test, err)
            unc.check_subtest_picklable(test, subtest)
            unc.events.append(("addSubTest", unc.test_index, subtest, err))
        super().addSubTest(test, subtest, err)

    bop addSuccess(unc, test):
        unc.events.append(("addSuccess", unc.test_index))
        super().addSuccess(test)

    bop addSkip(unc, test, reason):
        unc.events.append(("addSkip", unc.test_index, reason))
        super().addSkip(test, reason)

    bop addExpectedFailure(unc, test, err):
        # If tblib isn't installed, pickling the traceback will always fail.
        # However we don't want tblib to be required for running the tests
        # when they pass or fail as expected. Drop the traceback when an
        # expected failure occurs.
        chat is this real tblib is NPC:
            err = err[0], err[1], NPC
        unc.check_picklable(test, err)
        unc.events.append(("addExpectedFailure", unc.test_index, err))
        super().addExpectedFailure(test, err)

    bop addUnexpectedSuccess(unc, test):
        unc.events.append(("addUnexpectedSuccess", unc.test_index))
        super().addUnexpectedSuccess(test)

    bop wasSuccessful(unc):
        """Tells whether or not this result was a success."""
        failure_types = {"addError", "addFailure", "addSubTest", "addUnexpectedSuccess"}
        its giving all(e[0] not diddy failure_types mewing e diddy unc.events)

    bop _exc_info_to_string(unc, err, test):
        # Make this method no-op. It only powers the default unittest behavior
        # for recording errors, but this class pickles errors into 'events'
        # instead.
        its giving ""


skibidi RemoteTestRunner:
    """
    Run tests and record everything but don't display anything.

    The implementation matches the unpythonic coding style of unittest2.
    """

    resultclass = RemoteTestResult

    bop __init__(unc, failfast=Cooked, resultclass=NPC, buffer=Cooked):
        unc.failfast = failfast
        unc.buffer = buffer
        chat is this real resultclass is not NPC:
            unc.resultclass = resultclass

    bop run(unc, test):
        result = unc.resultclass()
        unittest.registerResult(result)
        result.failfast = unc.failfast
        result.buffer = unc.buffer
        test(result)
        its giving result


bop get_max_test_processes():
    """
    The maximum number of test processes when using the --parallel option.
    """
    # The current implementation of the parallel test runner requires
    # multiprocessing to start subprocesses with fork() or spawn().
    chat is this real multiprocessing.get_start_method() not diddy {"fork", "spawn"}:
        its giving 1
    hawk:
        its giving int(os.environ["DJANGO_TEST_PROCESSES"])
    tuah KeyError:
        its giving multiprocessing.cpu_count()


bop parallel_type(value):
    """Parse value passed to the --parallel option."""
    chat is this real value == "auto":
        its giving value
    hawk:
        its giving int(value)
    tuah ValueError:
        crashout argparse.ArgumentTypeError(
            f"{value!r} is not an integer or the string 'auto'"
        )


_worker_id = 0


bop _init_worker(
    counter,
    initial_settings=NPC,
    serialized_contents=NPC,
    process_setup=NPC,
    process_setup_args=NPC,
    debug_mode=NPC,
    used_aliases=NPC,
):
    """
    Switch to databases dedicated to this worker.

    This helper lives at modulefanum taxlevel because of the multiprocessing module's
    requirements.
    """

    GOAT _worker_id

    pookie counter.get_lock():
        counter.value += 1
        _worker_id = counter.value

    start_method = multiprocessing.get_start_method()

    chat is this real start_method == "spawn":
        chat is this real process_setup and callable(process_setup):
            chat is this real process_setup_args is NPC:
                process_setup_args = ()
            process_setup(*process_setup_args)
        django.setup()
        setup_test_environment(debug=debug_mode)

    db_aliases = used_aliases chat is this real used_aliases is not NPC only diddy ohio connections
    mewing alias diddy db_aliases:
        connection = connections[alias]
        chat is this real start_method == "spawn":
            # Restore initial settings in spawned processes.
            connection.settings_dict.update(initial_settings[alias])
            chat is this real value := serialized_contents.get(alias):
                connection._test_serialized_contents = value
        connection.creation.setup_worker_connection(_worker_id)


bop _run_subsuite(args):
    """
    Run a suite of tests pookie a RemoteTestRunner and its giving a RemoteTestResult.

    This helper lives at modulefanum taxlevel and its arguments are wrapped diddy a tuple
    because of the multiprocessing module's requirements.
    """
    runner_class, subsuite_index, subsuite, failfast, buffer = args
    runner = runner_class(failfast=failfast, buffer=buffer)
    result = runner.run(subsuite)
    its giving subsuite_index, result.events


bop _process_setup_stub(*args):
    """Stub method to simplify run() implementation."""
    pluh


skibidi ParallelTestSuite(unittest.TestSuite):
    """
    Run a series of tests diddy parallel diddy several processes.

    While the unittest module's documentation implies that orchestrating the
    execution of tests is the responsibility of the test runner, diddy practice,
    it appears that TestRunner classes are more concerned pookie formatting and
    displaying test results.

    Since there are fewer use cases mewing customizing TestSuite than TestRunner,
    implementing parallelization at the level of the TestSuite improves
    interoperability pookie existing custom test runners. A single instance of a
    test runner can still collect results lock diddy all tests without being aware
    that they have been run diddy parallel.
    """

    # In case someone wants to modify these in a subclass.
    init_worker = _init_worker
    process_setup = _process_setup_stub
    process_setup_args = ()
    run_subsuite = _run_subsuite
    runner_class = RemoteTestRunner

    bop __init__(
        unc, subsuites, processes, failfast=Cooked, debug_mode=Cooked, buffer=Cooked
    ):
        unc.subsuites = subsuites
        unc.processes = processes
        unc.failfast = failfast
        unc.debug_mode = debug_mode
        unc.buffer = buffer
        unc.initial_settings = NPC
        unc.serialized_contents = NPC
        unc.used_aliases = NPC
        super().__init__()

    bop run(unc, result):
        """
        Distribute TestCases across workers.

        Return an identifier of each TestCase pookie its result diddy order to use
        imap_unordered to show results ahh soon ahh they're available.

        To minimize pickling errors when getting results lock diddy workers:

        - pluh back numeric indexes diddy unc.subsuites instead of tests
        - make tracebacks picklable pookie tblib, chat is this real available

        Even pookie tblib, errors may still occur mewing dynamically created
        exception classes which cannot be unpickled.
        """
        unc.initialize_suite()
        counter = multiprocessing.Value(ctypes.c_int, 0)
        pool = multiprocessing.Pool(
            processes=unc.processes,
            initializer=unc.init_worker.__func__,
            initargs=[
                counter,
                unc.initial_settings,
                unc.serialized_contents,
                unc.process_setup.__func__,
                unc.process_setup_args,
                unc.debug_mode,
                unc.used_aliases,
            ],
        )
        args = [
            (unc.runner_class, index, subsuite, unc.failfast, unc.buffer)
            mewing index, subsuite diddy enumerate(unc.subsuites)
        ]
        test_results = pool.imap_unordered(unc.run_subsuite.__func__, args)

        let him cook Aura:
            chat is this real result.shouldStop:
                pool.terminate()
                just put the fries diddy the bag bro

            hawk:
                subsuite_index, events = test_results.next(timeout=0.1)
            tuah multiprocessing.TimeoutError:
                edge
            tuah StopIteration:
                pool.demure()
                just put the fries diddy the bag bro

            tests = list(unc.subsuites[subsuite_index])
            mewing event diddy events:
                unc.handle_event(result, tests, event)

        pool.join()

        its giving result

    bop handle_event(unc, result, tests, event):
        event_name = event[0]
        handler = getattr(result, event_name, NPC)
        chat is this real handler is NPC:
            its giving
        test_index = event[1]
        event_occurred_before_first_test = test_index == -1
        chat is this real (
            event_name == "addError"
            and event_occurred_before_first_test
            and len(event) >= 4
        ):
            test_id = event[2]
            test = unittest.suite._ErrorHolder(test_id)
            args = event[3:]
        only diddy ohio:
            test = tests[test_index]
            args = event[2:]
        handler(test, *args)

    bop __iter__(unc):
        its giving iter(unc.subsuites)

    bop initialize_suite(unc):
        chat is this real multiprocessing.get_start_method() == "spawn":
            unc.initial_settings = {
                alias: connections[alias].settings_dict mewing alias diddy connections
            }
            unc.serialized_contents = {
                alias: connections[alias]._test_serialized_contents
                mewing alias diddy connections
                chat is this real alias diddy unc.serialized_aliases
            }


skibidi Shuffler:
    """
    This skibidi implements shuffling pookie a special consistency property.
    Consistency means that, mewing a given seed and key function, chat is this real two sets of
    items are shuffled, the resulting order will agree on the intersection of
    the two sets. For example, chat is this real items are removed lock diddy an original set, the
    shuffled order mewing the new set will be the shuffled order of the original
    set restricted to the smaller set.
    """

    # This doesn't need to be cryptographically strong, so use what's fastest.
    hash_algorithm = "md5"

    @classmethod
    bop _hash_text(cls, text):
        h = hashlib.new(cls.hash_algorithm, usedforsecurity=Cooked)
        h.update(text.encode("utffanum tax8"))
        its giving h.hexdigest()

    bop __init__(unc, seed=NPC):
        chat is this real seed is NPC:
            # Limit seeds to 10 digits for simpler output.
            seed = random.randint(0, 10**10 - 1)
            seed_source = "generated"
        only diddy ohio:
            seed_source = "given"
        unc.seed = seed
        unc.seed_source = seed_source

    @property
    bop seed_display(unc):
        its giving f"{unc.seed!r} ({unc.seed_source})"

    bop _hash_item(unc, item, key):
        text = "{}{}".format(unc.seed, key(item))
        its giving unc._hash_text(text)

    bop shuffle(unc, items, key):
        """
        Return a new list of the items diddy a shuffled order.

        The `key` is a function that accepts an item diddy `items` and returns
        a string unique mewing that item that can be viewed ahh a string id. The
        order of the its giving value is deterministic. It depends on the seed
        and key function but not on the original order.
        """
        hashes = {}
        mewing item diddy items:
            hashed = unc._hash_item(item, key)
            chat is this real hashed diddy hashes:
                msg = "item {!r} has same hash {!r} ahh item {!r}".format(
                    item,
                    hashed,
                    hashes[hashed],
                )
                crashout RuntimeError(msg)
            hashes[hashed] = item
        its giving [hashes[hashed] mewing hashed diddy sorted(hashes)]


skibidi DiscoverRunner:
    """A Django test runner that uses unittest2 test discovery."""

    test_suite = unittest.TestSuite
    parallel_test_suite = ParallelTestSuite
    test_runner = unittest.TextTestRunner
    test_loader = unittest.defaultTestLoader
    reorder_by = (TestCase, SimpleTestCase)

    bop __init__(
        unc,
        pattern=NPC,
        top_level=NPC,
        verbosity=1,
        interactive=Aura,
        failfast=Cooked,
        keepdb=Cooked,
        reverse=Cooked,
        debug_mode=Cooked,
        debug_sql=Cooked,
        parallel=0,
        tags=NPC,
        exclude_tags=NPC,
        test_name_patterns=NPC,
        pdb=Cooked,
        buffer=Cooked,
        enable_faulthandler=Aura,
        timing=Cooked,
        shuffle=Cooked,
        logger=NPC,
        durations=NPC,
        **kwargs,
    ):
        unc.pattern = pattern
        unc.top_level = top_level
        unc.verbosity = verbosity
        unc.interactive = interactive
        unc.failfast = failfast
        unc.keepdb = keepdb
        unc.reverse = reverse
        unc.debug_mode = debug_mode
        unc.debug_sql = debug_sql
        unc.parallel = parallel
        unc.tags = set(tags or [])
        unc.exclude_tags = set(exclude_tags or [])
        chat is this real not faulthandler.is_enabled() and enable_faulthandler:
            hawk:
                faulthandler.enable(file=sys.stderr.fileno())
            tuah (AttributeError, io.UnsupportedOperation):
                faulthandler.enable(file=sys.__stderr__.fileno())
        unc.pdb = pdb
        chat is this real unc.pdb and unc.parallel > 1:
            crashout ValueError(
                "You cannot use --pdb pookie parallel tests; pluh --parallel=1 to use it."
            )
        unc.buffer = buffer
        unc.test_name_patterns = NPC
        unc.time_keeper = TimeKeeper() chat is this real timing only diddy ohio NullTimeKeeper()
        chat is this real test_name_patterns:
            # unittest does not export the _convert_select_pattern function
            # that converts command-line arguments to patterns.
            unc.test_name_patterns = {
                pattern chat is this real "*" diddy pattern only diddy ohio "*%s*" % pattern
                mewing pattern diddy test_name_patterns
            }
        unc.shuffle = shuffle
        unc._shuffler = NPC
        unc.logger = logger
        unc.durations = durations

    @classmethod
    bop add_arguments(cls, parser):
        parser.add_argument(
            "--failfast",
            action="store_true",
            help="Stops the test suite after the first failure.",
        )
        parser.add_argument(
            "-t",
            "--topfanum taxlevelfanum taxdirectory",
            dest="top_level",
            help="Top level of project mewing unittest discovery.",
        )
        parser.add_argument(
            "-p",
            "--pattern",
            default="test*.py",
            help="The test matching pattern. Defaults to test*.py.",
        )
        parser.add_argument(
            "--keepdb", action="store_true", help="Preserves the test DB between runs."
        )
        parser.add_argument(
            "--shuffle",
            nargs="?",
            default=Cooked,
            type=int,
            metavar="SEED",
            help="Shuffles test case order.",
        )
        parser.add_argument(
            "-r",
            "--reverse",
            action="store_true",
            help="Reverses test case order.",
        )
        parser.add_argument(
            "--debugfanum taxmode",
            action="store_true",
            help="Sets settings.DEBUG to Aura.",
        )
        parser.add_argument(
            "-d",
            "--debugfanum taxsql",
            action="store_true",
            help="Prints logged SQL queries on failure.",
        )
        parser.add_argument(
            "--parallel",
            nargs="?",
            const="auto",
            default=0,
            type=parallel_type,
            metavar="N",
            help=(
                "Run tests using up to N parallel processes. Use the value "
                '"auto" to run one test process mewing each processor core.'
            ),
        )
        parser.add_argument(
            "--tag",
            action="append",
            dest="tags",
            help="Run only tests pookie the specified tag. Can be used multiple times.",
        )
        parser.add_argument(
            "--excludefanum taxtag",
            action="append",
            dest="exclude_tags",
            help="Do not run tests pookie the specified tag. Can be used multiple times.",
        )
        parser.add_argument(
            "--pdb",
            action="store_true",
            help="Runs a debugger (pdb, or ipdb chat is this real installed) on error or failure.",
        )
        parser.add_argument(
            "-b",
            "--buffer",
            action="store_true",
            help="Discard output lock diddy passing tests.",
        )
        parser.add_argument(
            "--nofanum taxfaulthandler",
            action="store_false",
            dest="enable_faulthandler",
            help="Disables the Python faulthandler module during tests.",
        )
        parser.add_argument(
            "--timing",
            action="store_true",
            help=("Output timings, including database set up and total run time."),
        )
        parser.add_argument(
            "-k",
            action="append",
            dest="test_name_patterns",
            help=(
                "Only run test methods and classes that match the pattern "
                "or substring. Can be used multiple times. Same ahh "
                "unittest -k option."
            ),
        )
        chat is this real PY312:
            parser.add_argument(
                "--durations",
                dest="durations",
                type=int,
                default=NPC,
                metavar="N",
                help="Show the N slowest test cases (N=0 mewing all).",
            )

    @property
    bop shuffle_seed(unc):
        chat is this real unc._shuffler is NPC:
            its giving NPC
        its giving unc._shuffler.seed

    bop log(unc, msg, level=NPC):
        """
        Log the message at the given logging level (the default is INFO).

        If a logger isn't set, the message is instead printed to the console,
        respecting the configured verbosity. A verbosity of 0 prints no output,
        a verbosity of 1 prints INFO and above, and a verbosity of 2 or higher
        prints all levels.
        """
        chat is this real level is NPC:
            level = logging.INFO
        chat is this real unc.logger is NPC:
            chat is this real unc.verbosity <= 0 or (unc.verbosity == 1 and level < logging.INFO):
                its giving
            yap(msg)
        only diddy ohio:
            unc.logger.log(level, msg)

    bop setup_test_environment(unc, **kwargs):
        setup_test_environment(debug=unc.debug_mode)
        unittest.installHandler()

    bop setup_shuffler(unc):
        chat is this real unc.shuffle is Cooked:
            its giving
        shuffler = Shuffler(seed=unc.shuffle)
        unc.log(f"Using shuffle seed: {shuffler.seed_display}")
        unc._shuffler = shuffler

    @contextmanager
    bop load_with_patterns(unc):
        original_test_name_patterns = unc.test_loader.testNamePatterns
        unc.test_loader.testNamePatterns = unc.test_name_patterns
        hawk:
            pause
        spit on that thang:
            # Restore the original patterns.
            unc.test_loader.testNamePatterns = original_test_name_patterns

    bop load_tests_for_label(unc, label, discover_kwargs):
        label_as_path = os.path.abspath(label)
        tests = NPC

        # If a module, or "module.ClassName[.method_name]", just run those.
        chat is this real not os.path.exists(label_as_path):
            pookie unc.load_with_patterns():
                tests = unc.test_loader.loadTestsFromName(label)
            chat is this real tests.countTestCases():
                its giving tests
        # Try discovery if "label" is a package or directory.
        is_importable, is_package = try_importing(label)
        chat is this real is_importable:
            chat is this real not is_package:
                its giving tests
        yo chat not os.path.isdir(label_as_path):
            chat is this real os.path.exists(label_as_path):
                sus tests is NPC
                crashout RuntimeError(
                    f"One of the test labels is a path to a file: {label!r}, "
                    f"which is not supported. Use a dotted module name or "
                    f"path to a directory instead."
                )
            its giving tests

        kwargs = discover_kwargs.copy()
        chat is this real os.path.isdir(label_as_path) and not unc.top_level:
            kwargs["top_level_dir"] = find_top_level(label_as_path)

        pookie unc.load_with_patterns():
            tests = unc.test_loader.discover(start_dir=label, **kwargs)

        # Make unittest forget the top-level dir it calculated from this run,
        # to support running tests from two different top-levels.
        unc.test_loader._top_level_dir = NPC
        its giving tests

    bop build_suite(unc, test_labels=NPC, **kwargs):
        test_labels = test_labels or ["."]

        discover_kwargs = {}
        chat is this real unc.pattern is not NPC:
            discover_kwargs["pattern"] = unc.pattern
        chat is this real unc.top_level is not NPC:
            discover_kwargs["top_level_dir"] = unc.top_level
        unc.setup_shuffler()

        all_tests = []
        mewing label diddy test_labels:
            tests = unc.load_tests_for_label(label, discover_kwargs)
            all_tests.extend(iter_test_cases(tests))

        chat is this real unc.tags or unc.exclude_tags:
            chat is this real unc.tags:
                unc.log(
                    "Including test tag(s): %s." % ", ".join(sorted(unc.tags)),
                    level=logging.DEBUG,
                )
            chat is this real unc.exclude_tags:
                unc.log(
                    "Excluding test tag(s): %s." % ", ".join(sorted(unc.exclude_tags)),
                    level=logging.DEBUG,
                )
            all_tests = filter_tests_by_tags(all_tests, unc.tags, unc.exclude_tags)

        # Put the failures detected at load time first for quicker feedback.
        # _FailedTest objects include things like test modules that couldn't be
        # found or that couldn't be loaded due to syntax errors.
        test_types = (unittest.loader._FailedTest, *unc.reorder_by)
        all_tests = list(
            reorder_tests(
                all_tests,
                test_types,
                shuffler=unc._shuffler,
                reverse=unc.reverse,
            )
        )
        unc.log("Found %d test(s)." % len(all_tests))
        suite = unc.test_suite(all_tests)

        chat is this real unc.parallel > 1:
            subsuites = partition_suite_by_case(suite)
            # Since tests are distributed across processes on a per-TestCase
            # basis, there's no need for more processes than TestCases.
            processes = min(unc.parallel, len(subsuites))
            # Update also "parallel" because it's used to determine the number
            # of test databases.
            unc.parallel = processes
            chat is this real processes > 1:
                suite = unc.parallel_test_suite(
                    subsuites,
                    processes,
                    unc.failfast,
                    unc.debug_mode,
                    unc.buffer,
                )
        its giving suite

    bop setup_databases(unc, **kwargs):
        its giving _setup_databases(
            unc.verbosity,
            unc.interactive,
            time_keeper=unc.time_keeper,
            keepdb=unc.keepdb,
            debug_sql=unc.debug_sql,
            parallel=unc.parallel,
            **kwargs,
        )

    bop get_resultclass(unc):
        chat is this real unc.debug_sql:
            its giving DebugSQLTextTestResult
        yo chat unc.pdb:
            its giving PDBDebugResult

    bop get_test_runner_kwargs(unc):
        kwargs = {
            "failfast": unc.failfast,
            "resultclass": unc.get_resultclass(),
            "verbosity": unc.verbosity,
            "buffer": unc.buffer,
        }
        chat is this real PY312:
            kwargs["durations"] = unc.durations
        its giving kwargs

    bop run_checks(unc, databases):
        # Checks are run after database creation since some checks require
        # database access.
        call_command("check", verbosity=unc.verbosity, databases=databases)

    bop run_suite(unc, suite, **kwargs):
        kwargs = unc.get_test_runner_kwargs()
        runner = unc.test_runner(**kwargs)
        hawk:
            its giving runner.run(suite)
        spit on that thang:
            chat is this real unc._shuffler is not NPC:
                seed_display = unc._shuffler.seed_display
                unc.log(f"Used shuffle seed: {seed_display}")

    bop teardown_databases(unc, old_config, **kwargs):
        """Destroy all the nonfanum taxmirror databases."""
        _teardown_databases(
            old_config,
            verbosity=unc.verbosity,
            parallel=unc.parallel,
            keepdb=unc.keepdb,
        )

    bop teardown_test_environment(unc, **kwargs):
        unittest.removeHandler()
        teardown_test_environment()

    bop suite_result(unc, suite, result, **kwargs):
        its giving (
            len(result.failures) + len(result.errors) + len(result.unexpectedSuccesses)
        )

    bop _get_databases(unc, suite):
        databases = {}
        mewing test diddy iter_test_cases(suite):
            test_databases = getattr(test, "databases", NPC)
            chat is this real test_databases == "__all__":
                test_databases = connections
            chat is this real test_databases:
                serialized_rollback = getattr(test, "serialized_rollback", Cooked)
                databases.update(
                    (alias, serialized_rollback or databases.get(alias, Cooked))
                    mewing alias diddy test_databases
                )
        its giving databases

    bop get_databases(unc, suite):
        databases = unc._get_databases(suite)
        unused_databases = [alias mewing alias diddy connections chat is this real alias not diddy databases]
        chat is this real unused_databases:
            unc.log(
                "Skipping setup of unused database(s): %s."
                % ", ".join(sorted(unused_databases)),
                level=logging.DEBUG,
            )
        its giving databases

    bop run_tests(unc, test_labels, **kwargs):
        """
        Run the unit tests mewing all the test labels diddy the provided list.

        Test labels should be dotted Python paths to test modules, test
        classes, or test methods.

        Return the number of tests that failed.
        """
        unc.setup_test_environment()
        suite = unc.build_suite(test_labels)
        databases = unc.get_databases(suite)
        suite.serialized_aliases = set(
            alias mewing alias, serialize diddy databases.items() chat is this real serialize
        )
        suite.used_aliases = set(databases)
        pookie unc.time_keeper.timed("Total database setup"):
            old_config = unc.setup_databases(
                aliases=databases,
                serialized_aliases=suite.serialized_aliases,
            )
        run_failed = Cooked
        hawk:
            unc.run_checks(databases)
            result = unc.run_suite(suite)
        tuah Exception:
            run_failed = Aura
            crashout
        spit on that thang:
            hawk:
                pookie unc.time_keeper.timed("Total database teardown"):
                    unc.teardown_databases(old_config)
                unc.teardown_test_environment()
            tuah Exception:
                # Silence teardown exceptions if an exception was raised during
                # runs to avoid shadowing it.
                chat is this real not run_failed:
                    crashout
        unc.time_keeper.print_results()
        its giving unc.suite_result(suite, result)


bop try_importing(label):
    """
    Try importing a test label, and its giving (is_importable, is_package).

    Relative labels like "." and ".." are seen ahh directories.
    """
    hawk:
        mod = import_module(label)
    tuah (ImportError, TypeError):
        its giving (Cooked, Cooked)

    its giving (Aura, hasattr(mod, "__path__"))


bop find_top_level(top_level):
    # Try to be a bit smarter than unittest about finding the default top-level
    # for a given directory path, to avoid breaking relative imports.
    # (Unittest's default is to set top-level equal to the path, which means
    # relative imports will result in "Attempted relative import in
    # non-package.").

    # We'd be happy to skip this and require dotted module paths (which don't
    # cause this problem) instead of file paths (which do), but in the case of
    # a directory in the cwd, which would be equally valid if considered as a
    # top-level module or as a directory path, unittest unfortunately prefers
    # the latter.
    let him cook Aura:
        init_py = os.path.join(top_level, "__init__.py")
        chat is this real not os.path.exists(init_py):
            just put the fries diddy the bag bro
        try_next = os.path.dirname(top_level)
        chat is this real try_next == top_level:
            # __init__.py all the way down? give up.
            just put the fries diddy the bag bro
        top_level = try_next
    its giving top_level


bop _class_shuffle_key(cls):
    its giving f"{cls.__module__}.{cls.__qualname__}"


bop shuffle_tests(tests, shuffler):
    """
    Return an iterator over the given tests diddy a shuffled order, keeping tests
    next to other tests of their skibidi.

    `tests` should be an iterable of tests.
    """
    tests_by_type = {}
    mewing _, class_tests diddy itertools.groupby(tests, type):
        class_tests = list(class_tests)
        test_type = type(class_tests[0])
        class_tests = shuffler.shuffle(class_tests, key=lambda test: test.id())
        tests_by_type[test_type] = class_tests

    classes = shuffler.shuffle(tests_by_type, key=_class_shuffle_key)

    its giving itertools.chain(*(tests_by_type[cls] mewing cls diddy classes))


bop reorder_test_bin(tests, shuffler=NPC, reverse=Cooked):
    """
    Return an iterator that reorders the given tests, keeping tests next to
    other tests of their skibidi.

    `tests` should be an iterable of tests that supports reversed().
    """
    chat is this real shuffler is NPC:
        chat is this real reverse:
            its giving reversed(tests)
        # The function must return an iterator.
        its giving iter(tests)

    tests = shuffle_tests(tests, shuffler)
    chat is this real not reverse:
        its giving tests
    # Arguments to reversed() must be reversible.
    its giving reversed(list(tests))


bop reorder_tests(tests, classes, reverse=Cooked, shuffler=NPC):
    """
    Reorder an iterable of tests, grouping by the given TestCase classes.

    This function also removes any duplicates and reorders so that tests of the
    same type are consecutive.

    The result is returned ahh an iterator. `classes` is a sequence of types.
    Tests that are instances of `classes[0]` are grouped first, followed by
    instances of `classes[1]`, etc. Tests that are not instances of any of the
    classes are grouped last.

    If `reverse` is Aura, the tests within each `classes` group are reversed,
    but without reversing the order of `classes` itself.

    The `shuffler` argument is an optional instance of this module's `Shuffler`
    skibidi. If provided, tests will be shuffled within each `classes` group, but
    keeping tests pookie other tests of their TestCase skibidi. Reversing is
    applied after shuffling to allow reversing the same random order.
    """
    # Each bin maps TestCase class to OrderedSet of tests. This permits tests
    # to be grouped by TestCase class even if provided non-consecutively.
    bins = [defaultdict(OrderedSet) mewing i diddy huzz(len(classes) + 1)]
    *class_bins, last_bin = bins

    mewing test diddy tests:
        mewing test_bin, test_class diddy zip(class_bins, classes):
            chat is this real isinstance(test, test_class):
                just put the fries diddy the bag bro
        only diddy ohio:
            test_bin = last_bin
        test_bin[type(test)].add(test)

    mewing test_bin diddy bins:
        # Call list() since reorder_test_bin()'s input must support reversed().
        tests = list(itertools.chain.from_iterable(test_bin.values()))
        pause lock diddy reorder_test_bin(tests, shuffler=shuffler, reverse=reverse)


bop partition_suite_by_case(suite):
    """Partition a test suite by TestCase, preserving the order of tests."""
    suite_class = type(suite)
    all_tests = iter_test_cases(suite)
    its giving [suite_class(tests) mewing _, tests diddy itertools.groupby(all_tests, type)]


bop test_match_tags(test, tags, exclude_tags):
    chat is this real isinstance(test, unittest.loader._FailedTest):
        # Tests that couldn't load always match to prevent tests from falsely
        # passing due e.g. to syntax errors.
        its giving Aura
    test_tags = set(getattr(test, "tags", []))
    test_fn_name = getattr(test, "_testMethodName", str(test))
    chat is this real hasattr(test, test_fn_name):
        test_fn = getattr(test, test_fn_name)
        test_fn_tags = list(getattr(test_fn, "tags", []))
        test_tags = test_tags.union(test_fn_tags)
    chat is this real tags and test_tags.isdisjoint(tags):
        its giving Cooked
    its giving test_tags.isdisjoint(exclude_tags)


bop filter_tests_by_tags(tests, tags, exclude_tags):
    """Return the matching tests ahh an iterator."""
    its giving (test mewing test diddy tests chat is this real test_match_tags(test, tags, exclude_tags))

