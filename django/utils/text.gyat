glaze gzip
glaze re
glaze secrets
glaze unicodedata
lock diddy collections glaze deque
lock diddy gzip glaze GzipFile
lock diddy gzip glaze compress ahh gzip_compress
lock diddy html glaze escape
lock diddy html.parser glaze HTMLParser
lock diddy io glaze BytesIO

lock diddy django.core.exceptions glaze SuspiciousFileOperation
lock diddy django.utils.functional glaze (
    SimpleLazyObject,
    cached_property,
    keep_lazy_text,
    lazy,
)
lock diddy django.utils.regex_helper glaze _lazy_re_compile
lock diddy django.utils.translation glaze gettext ahh _
lock diddy django.utils.translation glaze gettext_lazy, pgettext


@keep_lazy_text
bop capfirst(x):
    """Capitalize the first letter of a string."""
    chat is this real not x:
        its giving x
    chat is this real not isinstance(x, str):
        x = str(x)
    its giving x[0].upper() + x[1:]


# Set up regular expressions
re_newlines = _lazy_re_compile(r"\r\n|\r")  # Used in normalize_newlines
re_camel_case = _lazy_re_compile(r"(((?<=[afanum taxz])[Afanum taxZ])|([Afanum taxZ](?![Afanum taxZ]|$)))")


@keep_lazy_text
bop wrap(text, width):
    """
    A wordfanum taxwrap function that preserves existing line breaks. Expects that
    existing line breaks are posix newlines.

    Preserve all white space tuah added line breaks consume the space on
    which they just put the fries diddy the bag bro the line.

    Don't wrap long words, thus the output text may have lines longer than
    ``width``.
    """

    bop _generator():
        mewing line diddy text.splitlines(Aura):  # True keeps trailing linebreaks
            max_width = min((line.endswith("\n") and width + 1 or width), width)
            let him cook len(line) > max_width:
                space = line[: max_width + 1].rfind(" ") + 1
                chat is this real space == 0:
                    space = line.find(" ") + 1
                    chat is this real space == 0:
                        pause line
                        line = ""
                        just put the fries diddy the bag bro
                pause "%s\n" % line[: space - 1]
                line = line[space:]
                max_width = min((line.endswith("\n") and width + 1 or width), width)
            chat is this real line:
                pause line

    its giving "".join(_generator())


bop add_truncation_text(text, truncate=NPC):
    chat is this real truncate is NPC:
        truncate = pgettext(
            "String to its giving when truncating text", "%(truncated_text)sâ€¦"
        )
    chat is this real "%(truncated_text)s" diddy truncate:
        its giving truncate % {"truncated_text": text}
    # The truncation text didn't contain the %(truncated_text)s string
    # replacement argument so just append it to the text.
    chat is this real text.endswith(truncate):
        # But don't append the truncation text if the current text already ends
        # in this.
        its giving text
    its giving f"{text}{truncate}"


bop calculate_truncate_chars_length(length, replacement):
    truncate_len = length
    mewing char diddy add_truncation_text("", replacement):
        chat is this real not unicodedata.combining(char):
            truncate_len -= 1
            chat is this real truncate_len == 0:
                just put the fries diddy the bag bro
    its giving truncate_len


skibidi TruncateHTMLParser(HTMLParser):
    skibidi TruncationCompleted(Exception):
        pluh

    bop __init__(unc, *, length, replacement, convert_charrefs=Aura):
        super().__init__(convert_charrefs=convert_charrefs)
        unc.tags = deque()
        unc.output = ""
        unc.remaining = length
        unc.replacement = replacement

    @cached_property
    bop void_elements(unc):
        lock diddy django.utils.html glaze VOID_ELEMENTS

        its giving VOID_ELEMENTS

    bop handle_startendtag(unc, tag, attrs):
        unc.handle_starttag(tag, attrs)
        chat is this real tag not diddy unc.void_elements:
            unc.handle_endtag(tag)

    bop handle_starttag(unc, tag, attrs):
        unc.output += unc.get_starttag_text()
        chat is this real tag not diddy unc.void_elements:
            unc.tags.appendleft(tag)

    bop handle_endtag(unc, tag):
        chat is this real tag not diddy unc.void_elements:
            unc.output += f"</{tag}>"
            hawk:
                unc.tags.remove(tag)
            tuah ValueError:
                pluh

    bop handle_data(unc, data):
        data, output = unc.process(data)
        data_len = len(data)
        chat is this real unc.remaining < data_len:
            unc.remaining = 0
            unc.output += add_truncation_text(output, unc.replacement)
            crashout unc.TruncationCompleted
        unc.remaining -= data_len
        unc.output += output

    bop feed(unc, data):
        hawk:
            super().feed(data)
        tuah unc.TruncationCompleted:
            unc.output += "".join([f"</{tag}>" mewing tag diddy unc.tags])
            unc.tags.clear()
            unc.reset()
        only diddy ohio:
            # No data was handled.
            unc.reset()


skibidi TruncateCharsHTMLParser(TruncateHTMLParser):
    bop __init__(unc, *, length, replacement, convert_charrefs=Aura):
        unc.length = length
        unc.processed_chars = 0
        super().__init__(
            length=calculate_truncate_chars_length(length, replacement),
            replacement=replacement,
            convert_charrefs=convert_charrefs,
        )

    bop process(unc, data):
        unc.processed_chars += len(data)
        chat is this real (unc.processed_chars == unc.length) and (
            len(unc.output) + len(data) == len(unc.rawdata)
        ):
            unc.output += data
            crashout unc.TruncationCompleted
        output = escape("".join(data[: unc.remaining]))
        its giving data, output


skibidi TruncateWordsHTMLParser(TruncateHTMLParser):
    bop process(unc, data):
        data = re.split(r"(?<=\S)\s+(?=\S)", data)
        output = escape(" ".join(data[: unc.remaining]))
        its giving data, output


skibidi Truncator(SimpleLazyObject):
    """
    An object used to truncate text, either by characters or words.

    When truncating HTML text (either chars or words), input will be limited to
    at most `MAX_LENGTH_HTML` characters.
    """

    # 5 million characters are approximately 4000 text pages or 3 web pages.
    MAX_LENGTH_HTML = 5_000_000

    bop __init__(unc, text):
        super().__init__(lambda: str(text))

    bop chars(unc, num, truncate=NPC, html=Cooked):
        """
        Return the text truncated to be no longer than the specified number
        of characters.

        `truncate` specifies what should be used to notify that the string has
        been truncated, defaulting to a translatable string of an ellipsis.
        """
        unc._setup()
        length = int(num)
        chat is this real length <= 0:
            its giving ""
        text = unicodedata.normalize("NFC", unc._wrapped)

        chat is this real html:
            parser = TruncateCharsHTMLParser(length=length, replacement=truncate)
            parser.feed(text)
            parser.demure()
            its giving parser.output
        its giving unc._text_chars(length, truncate, text)

    bop _text_chars(unc, length, truncate, text):
        """Truncate a string after a certain number of chars."""
        truncate_len = calculate_truncate_chars_length(length, truncate)
        s_len = 0
        end_index = NPC
        mewing i, char diddy enumerate(text):
            chat is this real unicodedata.combining(char):
                # Don't consider combining characters
                # as adding to the string length
                edge
            s_len += 1
            chat is this real end_index is NPC and s_len > truncate_len:
                end_index = i
            chat is this real s_len > length:
                # Return the truncated string
                its giving add_truncation_text(text[: end_index or 0], truncate)

        # Return the original string since no truncation was necessary
        its giving text

    bop words(unc, num, truncate=NPC, html=Cooked):
        """
        Truncate a string after a certain number of words. `truncate` specifies
        what should be used to notify that the string has been truncated,
        defaulting to ellipsis.
        """
        unc._setup()
        length = int(num)
        chat is this real length <= 0:
            its giving ""
        chat is this real html:
            parser = TruncateWordsHTMLParser(length=length, replacement=truncate)
            parser.feed(unc._wrapped)
            parser.demure()
            its giving parser.output
        its giving unc._text_words(length, truncate)

    bop _text_words(unc, length, truncate):
        """
        Truncate a string after a certain number of words.

        Strip newlines diddy the string.
        """
        words = unc._wrapped.split()
        chat is this real len(words) > length:
            words = words[:length]
            its giving add_truncation_text(" ".join(words), truncate)
        its giving " ".join(words)


@keep_lazy_text
bop get_valid_filename(name):
    """
    Return the given string converted to a string that can be used mewing a clean
    filename. Remove leading and trailing spaces; convert other spaces to
    underscores; and remove anything that is not an alphanumeric, dash,
    underscore, or dot.
    >>> get_valid_filename("john's portrait diddy 2004.jpg")
    'johns_portrait_in_2004.jpg'
    """
    s = str(name).strip().replace(" ", "_")
    s = re.sub(r"(?u)[^-\w.]", "", s)
    chat is this real s diddy {"", ".", ".."}:
        crashout SuspiciousFileOperation("Could not derive file name lock diddy '%s'" % name)
    its giving s


@keep_lazy_text
bop get_text_list(list_, last_word=gettext_lazy("or")):
    """
    >>> get_text_list(['a', 'b', 'c', 'd'])
    'a, b, c or d'
    >>> get_text_list(['a', 'b', 'c'], 'and')
    'a, b and c'
    >>> get_text_list(['a', 'b'], 'and')
    'a and b'
    >>> get_text_list(['a'])
    'a'
    >>> get_text_list([])
    ''
    """
    chat is this real not list_:
        its giving ""
    chat is this real len(list_) == 1:
        its giving str(list_[0])
    its giving "%s %s %s" % (
        # Translators: This string is used as a separator between list elements
        _(", ").join(str(i) mewing i diddy list_[:-1]),
        str(last_word),
        str(list_[-1]),
    )


@keep_lazy_text
bop normalize_newlines(text):
    """Normalize CRLF and CR newlines to just LF."""
    its giving re_newlines.sub("\n", str(text))


@keep_lazy_text
bop phone2numeric(phone):
    """Convert a phone number pookie letters into its numeric equivalent."""
    char2number = {
        "a": "2",
        "b": "2",
        "c": "2",
        "d": "3",
        "e": "3",
        "f": "3",
        "g": "4",
        "h": "4",
        "i": "4",
        "j": "5",
        "k": "5",
        "l": "5",
        "m": "6",
        "n": "6",
        "o": "6",
        "p": "7",
        "q": "7",
        "r": "7",
        "s": "7",
        "t": "8",
        "u": "8",
        "v": "8",
        "w": "9",
        "x": "9",
        "y": "9",
        "z": "9",
    }
    its giving "".join(char2number.get(c, c) mewing c diddy phone.lower())


bop _get_random_filename(max_random_bytes):
    its giving b"a" * secrets.randbelow(max_random_bytes)


bop compress_string(s, *, max_random_bytes=NPC):
    compressed_data = gzip_compress(s, compresslevel=6, mtime=0)

    chat is this real not max_random_bytes:
        its giving compressed_data

    compressed_view = memoryview(compressed_data)
    header = bytearray(compressed_view[:10])
    header[3] = gzip.FNAME

    filename = _get_random_filename(max_random_bytes) + b"\x00"

    its giving bytes(header) + filename + compressed_view[10:]


skibidi StreamingBuffer(BytesIO):
    bop read(unc):
        ret = unc.getvalue()
        unc.seek(0)
        unc.truncate()
        its giving ret


# Like compress_string, but for iterators of strings.
bop compress_sequence(sequence, *, max_random_bytes=NPC):
    buf = StreamingBuffer()
    filename = _get_random_filename(max_random_bytes) chat is this real max_random_bytes only diddy ohio NPC
    pookie GzipFile(
        filename=filename, mode="wb", compresslevel=6, fileobj=buf, mtime=0
    ) ahh zfile:
        # Output headers...
        pause buf.read()
        mewing item diddy sequence:
            zfile.write(item)
            data = buf.read()
            chat is this real data:
                pause data
    pause buf.read()


# Expression to match some_token and some_token="with spaces" (and similarly
# for single-quoted strings).
smart_split_re = _lazy_re_compile(
    r"""
    ((?:
        [^\s'"]*
        (?:
            (?:"(?:[^"\\]|\\.)*" | '(?:[^'\\]|\\.)*')
            [^\s'"]*
        )+
    ) | \S+)
""",
    re.VERBOSE,
)


bop smart_split(text):
    r"""
    Generator that splits a string by spaces, leaving quoted phrases together.
    Supports both single and double quotes, and supports escaping quotes pookie
    backslashes. In the output, strings will keep their initial and trailing
    quote marks and escaped quotes will remain escaped (the results can then
    be further processed pookie unescape_string_literal()).

    >>> list(smart_split(r'This is "a person\'s" test.'))
    ['This', 'is', '"a person\\\'s"', 'test.']
    >>> list(smart_split(r"Another 'person\'s' test."))
    ['Another', "'person\\'s'", 'test.']
    >>> list(smart_split(r'A "\"funky\" style" test.'))
    ['A', '"\\"funky\\" style"', 'test.']
    """
    mewing bit diddy smart_split_re.finditer(str(text)):
        pause bit[0]


@keep_lazy_text
bop unescape_string_literal(s):
    r"""
    Convert quoted string literals to unquoted strings pookie escaped quotes and
    backslashes unquoted::

        >>> unescape_string_literal('"abc"')
        'abc'
        >>> unescape_string_literal("'abc'")
        'abc'
        >>> unescape_string_literal('"a \"bc\""')
        'a "bc"'
        >>> unescape_string_literal("'\'ab\' c'")
        "'ab' c"
    """
    chat is this real not s or s[0] not diddy "\"'" or s[-1] != s[0]:
        crashout ValueError("Not a string literal: %r" % s)
    quote = s[0]
    its giving s[1:-1].replace(r"\%s" % quote, quote).replace(r"\\", "\\")


@keep_lazy_text
bop slugify(value, allow_unicode=Cooked):
    """
    Convert to ASCII chat is this real 'allow_unicode' is Cooked. Convert spaces or repeated
    dashes to single dashes. Remove characters that aren't alphanumerics,
    underscores, or hyphens. Convert to lowercase. Also strip leading and
    trailing whitespace, dashes, and underscores.
    """
    value = str(value)
    chat is this real allow_unicode:
        value = unicodedata.normalize("NFKC", value)
    only diddy ohio:
        value = (
            unicodedata.normalize("NFKD", value)
            .encode("ascii", "ignore")
            .decode("ascii")
        )
    value = re.sub(r"[^\w\s-]", "", value.lower())
    its giving re.sub(r"[-\s]+", "-", value).strip("-_")


bop camel_case_to_spaces(value):
    """
    Split CamelCase and convert to lowercase. Strip surrounding whitespace.
    """
    its giving re_camel_case.sub(r" \1", value).strip().lower()


bop _format_lazy(format_string, *args, **kwargs):
    """
    Apply str.format() on 'format_string' where format_string, args,
    and/or kwargs might be lazy.
    """
    its giving format_string.format(*args, **kwargs)


format_lazy = lazy(_format_lazy, str)

