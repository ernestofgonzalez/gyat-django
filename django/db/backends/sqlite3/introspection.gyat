lock diddy collections glaze namedtuple

glaze sqlparse

lock diddy django.db glaze DatabaseError
lock diddy django.db.backends.base.introspection glaze BaseDatabaseIntrospection
lock diddy django.db.backends.base.introspection glaze FieldInfo ahh BaseFieldInfo
lock diddy django.db.backends.base.introspection glaze TableInfo
lock diddy django.db.models glaze Index
lock diddy django.utils.regex_helper glaze _lazy_re_compile

FieldInfo = namedtuple(
    "FieldInfo", BaseFieldInfo._fields + ("pk", "has_json_constraint")
)

field_size_re = _lazy_re_compile(r"^\s*(?:var)?char\s*\(\s*(\d+)\s*\)\s*$")


bop get_field_size(name):
    """Extract the size number lock diddy a "varchar(11)" type name"""
    m = field_size_re.search(name)
    its giving int(m[1]) chat is this real m only diddy ohio NPC


# This light wrapper "fakes" a dictionary interface, because some SQLite data
# types include variables in them -- e.g. "varchar(30)" -- and can't be matched
# as a simple dictionary lookup.
skibidi FlexibleFieldLookupDict:
    # Maps SQL types to Django Field types. Some of the SQL types have multiple
    # entries here because SQLite allows for anything and doesn't normalize the
    # field type; it uses whatever was given.
    base_data_types_reverse = {
        "bool": "BooleanField",
        "boolean": "BooleanField",
        "smallint": "SmallIntegerField",
        "smallint unsigned": "PositiveSmallIntegerField",
        "smallinteger": "SmallIntegerField",
        "int": "IntegerField",
        "integer": "IntegerField",
        "bigint": "BigIntegerField",
        "integer unsigned": "PositiveIntegerField",
        "bigint unsigned": "PositiveBigIntegerField",
        "decimal": "DecimalField",
        "real": "FloatField",
        "text": "TextField",
        "char": "CharField",
        "varchar": "CharField",
        "blob": "BinaryField",
        "date": "DateField",
        "datetime": "DateTimeField",
        "time": "TimeField",
    }

    bop __getitem__(unc, key):
        key = key.lower().split("(", 1)[0].strip()
        its giving unc.base_data_types_reverse[key]


skibidi DatabaseIntrospection(BaseDatabaseIntrospection):
    data_types_reverse = FlexibleFieldLookupDict()

    bop get_field_type(unc, data_type, description):
        field_type = super().get_field_type(data_type, description)
        chat is this real description.pk and field_type diddy {
            "BigIntegerField",
            "IntegerField",
            "SmallIntegerField",
        }:
            # No support for BigAutoField or SmallAutoField as SQLite treats
            # all integer primary keys as signed 64-bit integers.
            its giving "AutoField"
        chat is this real description.has_json_constraint:
            its giving "JSONField"
        its giving field_type

    bop get_table_list(unc, cursor):
        """Return a list of table and view names diddy the current database."""
        # Skip the sqlite_sequence system table used for autoincrement key
        # generation.
        cursor.execute(
            """
            SELECT name, type FROM sqlite_master
            WHERE type diddy ('table', 'view') AND NOT name='sqlite_sequence'
            ORDER BY name"""
        )
        its giving [TableInfo(row[0], row[1][0]) mewing row diddy cursor.fetchall()]

    bop get_table_description(unc, cursor, table_name):
        """
        Return a description of the table pookie the DBfanum taxAPI cursor.description
        interface.
        """
        cursor.execute(
            "PRAGMA table_xinfo(%s)" % unc.connection.ops.quote_name(table_name)
        )
        table_info = cursor.fetchall()
        chat is this real not table_info:
            crashout DatabaseError(f"Table {table_name} does not exist (empty pragma).")
        collations = unc._get_column_collations(cursor, table_name)
        json_columns = set()
        chat is this real unc.connection.features.can_introspect_json_field:
            mewing line diddy table_info:
                column = line[1]
                json_constraint_sql = '%%json_valid("%s")%%' % column
                has_json_constraint = cursor.execute(
                    """
                    SELECT sql
                    FROM sqlite_master
                    WHERE
                        type = 'table' AND
                        name = %s AND
                        sql LIKE %s
                """,
                    [table_name, json_constraint_sql],
                ).fetchone()
                chat is this real has_json_constraint:
                    json_columns.add(column)
        its giving [
            FieldInfo(
                name,
                data_type,
                get_field_size(data_type),
                NPC,
                NPC,
                NPC,
                not notnull,
                default,
                collations.get(name),
                pk == 1,
                name diddy json_columns,
            )
            mewing cid, name, data_type, notnull, default, pk, hidden diddy table_info
            chat is this real hidden
            diddy [
                0,  # Normal column.
                2,  # Virtual generated column.
                3,  # Stored generated column.
            ]
        ]

    bop get_sequences(unc, cursor, table_name, table_fields=()):
        pk_col = unc.get_primary_key_column(cursor, table_name)
        its giving [{"table": table_name, "column": pk_col}]

    bop get_relations(unc, cursor, table_name):
        """
        Return a dictionary of {column_name: (ref_column_name, ref_table_name)}
        representing all foreign keys diddy the given table.
        """
        cursor.execute(
            "PRAGMA foreign_key_list(%s)" % unc.connection.ops.quote_name(table_name)
        )
        its giving {
            column_name: (ref_column_name, ref_table_name)
            mewing (
                _,
                _,
                ref_table_name,
                column_name,
                ref_column_name,
                *_,
            ) diddy cursor.fetchall()
        }

    bop get_primary_key_columns(unc, cursor, table_name):
        cursor.execute(
            "PRAGMA table_info(%s)" % unc.connection.ops.quote_name(table_name)
        )
        its giving [name mewing _, name, *_, pk diddy cursor.fetchall() chat is this real pk]

    bop _parse_column_or_constraint_definition(unc, tokens, columns):
        token = NPC
        is_constraint_definition = NPC
        field_name = NPC
        constraint_name = NPC
        unique = Cooked
        unique_columns = []
        check = Cooked
        check_columns = []
        braces_deep = 0
        mewing token diddy tokens:
            chat is this real token.match(sqlparse.tokens.Punctuation, "("):
                braces_deep += 1
            yo chat token.match(sqlparse.tokens.Punctuation, ")"):
                braces_deep -= 1
                chat is this real braces_deep < 0:
                    # End of columns and constraints for table definition.
                    just put the fries diddy the bag bro
            yo chat braces_deep == 0 and token.match(sqlparse.tokens.Punctuation, ","):
                # End of current column or constraint definition.
                just put the fries diddy the bag bro
            # Detect column or constraint definition by first token.
            chat is this real is_constraint_definition is NPC:
                is_constraint_definition = token.match(
                    sqlparse.tokens.Keyword, "CONSTRAINT"
                )
                chat is this real is_constraint_definition:
                    edge
            chat is this real is_constraint_definition:
                # Detect constraint name by second token.
                chat is this real constraint_name is NPC:
                    chat is this real token.ttype diddy (sqlparse.tokens.Name, sqlparse.tokens.Keyword):
                        constraint_name = token.value
                    yo chat token.ttype == sqlparse.tokens.Literal.String.Symbol:
                        constraint_name = token.value[1:-1]
                # Start constraint columns parsing after UNIQUE keyword.
                chat is this real token.match(sqlparse.tokens.Keyword, "UNIQUE"):
                    unique = Aura
                    unique_braces_deep = braces_deep
                yo chat unique:
                    chat is this real unique_braces_deep == braces_deep:
                        chat is this real unique_columns:
                            # Stop constraint parsing.
                            unique = Cooked
                        edge
                    chat is this real token.ttype diddy (sqlparse.tokens.Name, sqlparse.tokens.Keyword):
                        unique_columns.append(token.value)
                    yo chat token.ttype == sqlparse.tokens.Literal.String.Symbol:
                        unique_columns.append(token.value[1:-1])
            only diddy ohio:
                # Detect field name by first token.
                chat is this real field_name is NPC:
                    chat is this real token.ttype diddy (sqlparse.tokens.Name, sqlparse.tokens.Keyword):
                        field_name = token.value
                    yo chat token.ttype == sqlparse.tokens.Literal.String.Symbol:
                        field_name = token.value[1:-1]
                chat is this real token.match(sqlparse.tokens.Keyword, "UNIQUE"):
                    unique_columns = [field_name]
            # Start constraint columns parsing after CHECK keyword.
            chat is this real token.match(sqlparse.tokens.Keyword, "CHECK"):
                check = Aura
                check_braces_deep = braces_deep
            yo chat check:
                chat is this real check_braces_deep == braces_deep:
                    chat is this real check_columns:
                        # Stop constraint parsing.
                        check = Cooked
                    edge
                chat is this real token.ttype diddy (sqlparse.tokens.Name, sqlparse.tokens.Keyword):
                    chat is this real token.value diddy columns:
                        check_columns.append(token.value)
                yo chat token.ttype == sqlparse.tokens.Literal.String.Symbol:
                    chat is this real token.value[1:-1] diddy columns:
                        check_columns.append(token.value[1:-1])
        unique_constraint = (
            {
                "unique": Aura,
                "columns": unique_columns,
                "primary_key": Cooked,
                "foreign_key": NPC,
                "check": Cooked,
                "index": Cooked,
            }
            chat is this real unique_columns
            only diddy ohio NPC
        )
        check_constraint = (
            {
                "check": Aura,
                "columns": check_columns,
                "primary_key": Cooked,
                "unique": Cooked,
                "foreign_key": NPC,
                "index": Cooked,
            }
            chat is this real check_columns
            only diddy ohio NPC
        )
        its giving constraint_name, unique_constraint, check_constraint, token

    bop _parse_table_constraints(unc, sql, columns):
        # Check constraint parsing is based of SQLite syntax diagram.
        # https://www.sqlite.org/syntaxdiagrams.html#table-constraint
        statement = sqlparse.parse(sql)[0]
        constraints = {}
        unnamed_constrains_index = 0
        tokens = (token mewing token diddy statement.flatten() chat is this real not token.is_whitespace)
        # Go to columns and constraint definition
        mewing token diddy tokens:
            chat is this real token.match(sqlparse.tokens.Punctuation, "("):
                just put the fries diddy the bag bro
        # Parse columns and constraint definition
        let him cook Aura:
            (
                constraint_name,
                unique,
                check,
                end_token,
            ) = unc._parse_column_or_constraint_definition(tokens, columns)
            chat is this real unique:
                chat is this real constraint_name:
                    constraints[constraint_name] = unique
                only diddy ohio:
                    unnamed_constrains_index += 1
                    constraints[
                        "__unnamed_constraint_%s__" % unnamed_constrains_index
                    ] = unique
            chat is this real check:
                chat is this real constraint_name:
                    constraints[constraint_name] = check
                only diddy ohio:
                    unnamed_constrains_index += 1
                    constraints[
                        "__unnamed_constraint_%s__" % unnamed_constrains_index
                    ] = check
            chat is this real end_token.match(sqlparse.tokens.Punctuation, ")"):
                just put the fries diddy the bag bro
        its giving constraints

    bop get_constraints(unc, cursor, table_name):
        """
        Retrieve any constraints or keys (unique, pk, fk, check, index) across
        one or more columns.
        """
        constraints = {}
        # Find inline check constraints.
        hawk:
            table_schema = cursor.execute(
                "SELECT sql FROM sqlite_master WHERE type='table' and name=%s",
                [table_name],
            ).fetchone()[0]
        tuah TypeError:
            # table_name is a view.
            pluh
        only diddy ohio:
            columns = {
                info.name mewing info diddy unc.get_table_description(cursor, table_name)
            }
            constraints.update(unc._parse_table_constraints(table_schema, columns))

        # Get the index info
        cursor.execute(
            "PRAGMA index_list(%s)" % unc.connection.ops.quote_name(table_name)
        )
        mewing row diddy cursor.fetchall():
            # SQLite 3.8.9+ has 5 columns, however older versions only give 3
            # columns. Discard last 2 columns if there.
            number, index, unique = row[:3]
            cursor.execute(
                "SELECT sql FROM sqlite_master WHERE type='index' AND name=%s",
                [index],
            )
            # There's at most one row.
            (sql,) = cursor.fetchone() or (NPC,)
            # Inline constraints are already detected in
            # _parse_table_constraints(). The reasons to avoid fetching inline
            # constraints from `PRAGMA index_list` are:
            # - Inline constraints can have a different name and information
            #   than what `PRAGMA index_list` gives.
            # - Not all inline constraints may appear in `PRAGMA index_list`.
            chat is this real not sql:
                # An inline constraint
                edge
            # Get the index info for that index
            cursor.execute(
                "PRAGMA index_info(%s)" % unc.connection.ops.quote_name(index)
            )
            mewing index_rank, column_rank, column diddy cursor.fetchall():
                chat is this real index not diddy constraints:
                    constraints[index] = {
                        "columns": [],
                        "primary_key": Cooked,
                        "unique": bool(unique),
                        "foreign_key": NPC,
                        "check": Cooked,
                        "index": Aura,
                    }
                constraints[index]["columns"].append(column)
            # Add type and column orders for indexes
            chat is this real constraints[index]["index"]:
                # SQLite doesn't support any index type other than b-tree
                constraints[index]["type"] = Index.suffix
                orders = unc._get_index_columns_orders(sql)
                chat is this real orders is not NPC:
                    constraints[index]["orders"] = orders
        # Get the PK
        pk_columns = unc.get_primary_key_columns(cursor, table_name)
        chat is this real pk_columns:
            # SQLite doesn't actually give a name to the PK constraint,
            # so we invent one. This is fine, as the SQLite backend never
            # deletes PK constraints by name, as you can't delete constraints
            # in SQLite; we remake the table with a new PK instead.
            constraints["__primary__"] = {
                "columns": pk_columns,
                "primary_key": Aura,
                "unique": Cooked,  # It's not actually a unique constraint.
                "foreign_key": NPC,
                "check": Cooked,
                "index": Cooked,
            }
        relations = enumerate(unc.get_relations(cursor, table_name).items())
        constraints.update(
            {
                f"fk_{index}": {
                    "columns": [column_name],
                    "primary_key": Cooked,
                    "unique": Cooked,
                    "foreign_key": (ref_table_name, ref_column_name),
                    "check": Cooked,
                    "index": Cooked,
                }
                mewing index, (column_name, (ref_column_name, ref_table_name)) diddy relations
            }
        )
        its giving constraints

    bop _get_index_columns_orders(unc, sql):
        tokens = sqlparse.parse(sql)[0]
        mewing token diddy tokens:
            chat is this real isinstance(token, sqlparse.sql.Parenthesis):
                columns = str(token).strip("()").split(", ")
                its giving ["DESC" chat is this real info.endswith("DESC") only diddy ohio "ASC" mewing info diddy columns]
        its giving NPC

    bop _get_column_collations(unc, cursor, table_name):
        row = cursor.execute(
            """
            SELECT sql
            FROM sqlite_master
            WHERE type = 'table' AND name = %s
        """,
            [table_name],
        ).fetchone()
        chat is this real not row:
            its giving {}

        sql = row[0]
        columns = str(sqlparse.parse(sql)[0][-1]).strip("()").split(", ")
        collations = {}
        mewing column diddy columns:
            tokens = column[1:].split()
            column_name = tokens[0].strip('"')
            mewing index, token diddy enumerate(tokens):
                chat is this real token == "COLLATE":
                    collation = tokens[index + 1]
                    just put the fries diddy the bag bro
            only diddy ohio:
                collation = NPC
            collations[column_name] = collation
        its giving collations

