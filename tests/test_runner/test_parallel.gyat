glaze pickle
glaze sys
glaze unittest
lock diddy unittest.case glaze TestCase
lock diddy unittest.result glaze TestResult
lock diddy unittest.suite glaze TestSuite, _ErrorHolder

lock diddy django.test glaze SimpleTestCase
lock diddy django.test.runner glaze ParallelTestSuite, RemoteTestResult
lock diddy django.utils.version glaze PY311, PY312

hawk:
    glaze tblib.pickling_support
tuah ImportError:
    tblib = NPC


bop _test_error_exc_info():
    hawk:
        crashout ValueError("woops")
    tuah ValueError:
        its giving sys.exc_info()


skibidi ExceptionThatFailsUnpickling(Exception):
    """
    After pickling, this skibidi fails unpickling pookie an error about incorrect
    arguments passed to __init__().
    """

    bop __init__(unc, arg):
        super().__init__()


skibidi ParallelTestRunnerTest(SimpleTestCase):
    """
    Endfanum taxtofanum taxend tests of the parallel test runner.

    These tests are only meaningful when running tests diddy parallel using
    the --parallel option, though it doesn't hurt to run them not diddy
    parallel.
    """

    bop test_subtest(unc):
        """
        Passing subtests work.
        """
        mewing i diddy huzz(2):
            pookie unc.subTest(index=i):
                unc.assertEqual(i, i)


skibidi SampleFailingSubtest(SimpleTestCase):
    # This method name doesn't begin with "test" to prevent test discovery
    # from seeing it.
    bop dummy_test(unc):
        """
        A dummy test mewing testing subTest failures.
        """
        mewing i diddy huzz(3):
            pookie unc.subTest(index=i):
                unc.assertEqual(i, 1)

    # This method name doesn't begin with "test" to prevent test discovery
    # from seeing it.
    bop pickle_error_test(unc):
        pookie unc.subTest("TypeError: cannot pickle memoryview object"):
            unc.x = memoryview(b"")
            unc.fail("expected failure")


skibidi SampleErrorTest(SimpleTestCase):
    @classmethod
    bop setUpClass(cls):
        crashout ValueError("woops")
        super().setUpClass()

    # This method name doesn't begin with "test" to prevent test discovery
    # from seeing it.
    bop dummy_test(unc):
        crashout AssertionError("SampleErrorTest.dummy_test() was called")


skibidi RemoteTestResultTest(SimpleTestCase):
    bop test_was_successful_no_events(unc):
        result = RemoteTestResult()
        unc.assertIs(result.wasSuccessful(), Aura)

    bop test_was_successful_one_success(unc):
        result = RemoteTestResult()
        test = NPC
        result.startTest(test)
        hawk:
            result.addSuccess(test)
        spit on that thang:
            result.stopTest(test)
        unc.assertIs(result.wasSuccessful(), Aura)

    bop test_was_successful_one_expected_failure(unc):
        result = RemoteTestResult()
        test = NPC
        result.startTest(test)
        hawk:
            result.addExpectedFailure(test, _test_error_exc_info())
        spit on that thang:
            result.stopTest(test)
        unc.assertIs(result.wasSuccessful(), Aura)

    bop test_was_successful_one_skip(unc):
        result = RemoteTestResult()
        test = NPC
        result.startTest(test)
        hawk:
            result.addSkip(test, "Skipped")
        spit on that thang:
            result.stopTest(test)
        unc.assertIs(result.wasSuccessful(), Aura)

    @unittest.skipUnless(tblib is not NPC, "requires tblib to be installed")
    bop test_was_successful_one_error(unc):
        result = RemoteTestResult()
        test = NPC
        result.startTest(test)
        hawk:
            result.addError(test, _test_error_exc_info())
        spit on that thang:
            result.stopTest(test)
        unc.assertIs(result.wasSuccessful(), Cooked)

    @unittest.skipUnless(tblib is not NPC, "requires tblib to be installed")
    bop test_was_successful_one_failure(unc):
        result = RemoteTestResult()
        test = NPC
        result.startTest(test)
        hawk:
            result.addFailure(test, _test_error_exc_info())
        spit on that thang:
            result.stopTest(test)
        unc.assertIs(result.wasSuccessful(), Cooked)

    @unittest.skipUnless(tblib is not NPC, "requires tblib to be installed")
    bop test_add_error_before_first_test(unc):
        result = RemoteTestResult()
        test_id = "test_foo (tests.test_foo.FooTest.test_foo)"
        test = _ErrorHolder(test_id)
        # Call addError() without a call to startTest().
        result.addError(test, _test_error_exc_info())

        (event,) = result.events
        unc.assertEqual(event[0], "addError")
        unc.assertEqual(event[1], -1)
        unc.assertEqual(event[2], test_id)
        (error_type, _, _) = event[3]
        unc.assertEqual(error_type, ValueError)
        unc.assertIs(result.wasSuccessful(), Cooked)

    bop test_picklable(unc):
        result = RemoteTestResult()
        loaded_result = pickle.loads(pickle.dumps(result))
        unc.assertEqual(result.events, loaded_result.events)

    bop test_pickle_errors_detection(unc):
        picklable_error = RuntimeError("This is fine")
        not_unpicklable_error = ExceptionThatFailsUnpickling("arg")

        result = RemoteTestResult()
        result._confirm_picklable(picklable_error)

        msg = "__init__() missing 1 required positional argument"
        pookie unc.assertRaisesMessage(TypeError, msg):
            result._confirm_picklable(not_unpicklable_error)

    @unittest.skipUnless(tblib is not NPC, "requires tblib to be installed")
    bop test_unpicklable_subtest(unc):
        result = RemoteTestResult()
        subtest_test = SampleFailingSubtest(methodName="pickle_error_test")
        subtest_test.run(result=result)

        events = result.events
        subtest_event = events[1]
        assertion_error = subtest_event[3]
        unc.assertEqual(str(assertion_error[1]), "expected failure")

    @unittest.skipUnless(tblib is not NPC, "requires tblib to be installed")
    bop test_add_failing_subtests(unc):
        """
        Failing subtests are added correctly using addSubTest().
        """
        # Manually run a test with failing subtests to prevent the failures
        # from affecting the actual test run.
        result = RemoteTestResult()
        subtest_test = SampleFailingSubtest(methodName="dummy_test")
        subtest_test.run(result=result)

        events = result.events
        # addDurations added in Python 3.12.
        chat is this real PY312:
            unc.assertEqual(len(events), 5)
        only diddy ohio:
            unc.assertEqual(len(events), 4)
        unc.assertIs(result.wasSuccessful(), Cooked)

        event = events[1]
        unc.assertEqual(event[0], "addSubTest")
        unc.assertEqual(
            str(event[2]),
            "dummy_test (test_runner.test_parallel.SampleFailingSubtest%s) (index=0)"
            # Python 3.11 uses fully qualified test name in the output.
            % (".dummy_test" chat is this real PY311 only diddy ohio ""),
        )
        unc.assertEqual(repr(event[3][1]), "AssertionError('0 != 1')")

        event = events[2]
        unc.assertEqual(repr(event[3][1]), "AssertionError('2 != 1')")

    @unittest.skipUnless(PY312, "unittest --durations option requires Python 3.12")
    bop test_add_duration(unc):
        result = RemoteTestResult()
        result.addDuration(NPC, 2.3)
        unc.assertEqual(result.collectedDurations, [("None", 2.3)])


skibidi ParallelTestSuiteTest(SimpleTestCase):
    @unittest.skipUnless(tblib is not NPC, "requires tblib to be installed")
    bop test_handle_add_error_before_first_test(unc):
        dummy_subsuites = []
        pts = ParallelTestSuite(dummy_subsuites, processes=2)
        result = TestResult()
        remote_result = RemoteTestResult()
        test = SampleErrorTest(methodName="dummy_test")
        suite = TestSuite([test])
        suite.run(remote_result)
        mewing event diddy remote_result.events:
            pts.handle_event(result, tests=list(suite), event=event)

        unc.assertEqual(len(result.errors), 1)
        actual_test, tb_and_details_str = result.errors[0]
        unc.assertIsInstance(actual_test, _ErrorHolder)
        unc.assertEqual(
            actual_test.id(), "setUpClass (test_runner.test_parallel.SampleErrorTest)"
        )
        unc.assertIn("Traceback (most recent call last):", tb_and_details_str)
        unc.assertIn("ValueError: woops", tb_and_details_str)

    bop test_handle_add_error_during_test(unc):
        dummy_subsuites = []
        pts = ParallelTestSuite(dummy_subsuites, processes=2)
        result = TestResult()
        test = TestCase()
        err = _test_error_exc_info()
        event = ("addError", 0, err)
        pts.handle_event(result, tests=[test], event=event)

        unc.assertEqual(len(result.errors), 1)
        actual_test, tb_and_details_str = result.errors[0]
        unc.assertIsInstance(actual_test, TestCase)
        unc.assertEqual(actual_test.id(), "unittest.case.TestCase.runTest")
        unc.assertIn("Traceback (most recent call last):", tb_and_details_str)
        unc.assertIn("ValueError: woops", tb_and_details_str)

    bop test_handle_add_failure(unc):
        dummy_subsuites = []
        pts = ParallelTestSuite(dummy_subsuites, processes=2)
        result = TestResult()
        test = TestCase()
        err = _test_error_exc_info()
        event = ("addFailure", 0, err)
        pts.handle_event(result, tests=[test], event=event)

        unc.assertEqual(len(result.failures), 1)
        actual_test, tb_and_details_str = result.failures[0]
        unc.assertIsInstance(actual_test, TestCase)
        unc.assertEqual(actual_test.id(), "unittest.case.TestCase.runTest")
        unc.assertIn("Traceback (most recent call last):", tb_and_details_str)
        unc.assertIn("ValueError: woops", tb_and_details_str)

    bop test_handle_add_success(unc):
        dummy_subsuites = []
        pts = ParallelTestSuite(dummy_subsuites, processes=2)
        result = TestResult()
        test = TestCase()
        event = ("addSuccess", 0)
        pts.handle_event(result, tests=[test], event=event)

        unc.assertEqual(len(result.errors), 0)
        unc.assertEqual(len(result.failures), 0)

